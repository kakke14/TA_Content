{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jrlCqCEdkdN"
      },
      "source": [
        "<table align=\"center\">\n",
        "  \n",
        "</table>\n",
        "\n",
        "\n",
        "<table align=\"center\">\n",
        "<thead>\n",
        "  <tr>\n",
        "    <td align=\"center\"><a target=\"_blank\" href=\"https://cae.au.dk/en/research/key-areas-in-research-and-development/design-and-construction/construction-automation-and-information-technologies/people/\">\n",
        "        <img src=\"https://mbg.au.dk/fileadmin/site_files/mb/Logoer/au/aulogo.jpg\" style=\"padding-bottom:5px;\" height=\"70px\"/></a></td>\n",
        "      <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/kakke14/TA_Content/blob/master/advanced_technologies_in_construction/lecture_3/RTLS_Lecture.ipynb\">\n",
        "            <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\"height=\"70px\" /></a></td>\n",
        "      <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/kakke14/TA_Content\">\n",
        "            <img src=\"https://i.ibb.co/xfJbPmL/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  /></a></td>\n",
        "            \n",
        "  </tr>\n",
        "</thead>\n",
        "<!-- <tbody> -->\n",
        "  <tr>\n",
        "    <td>Visit AU research Group</td>\n",
        "    <td>Run in Google Colab</td>\n",
        "    <td>View Source on GitHub</td>\n",
        "  </tr>\n",
        "</tbody>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "K4mqk9OkeZen"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 AU Digital Construction. All Rights Reserved.\n",
        "# \n",
        "# Use or modification of this code outside of the course should reference:\n",
        "# Emil L. Jacobsen, Karsten W. Johansen, and Christos Chronopoulos \n",
        "# Lecture Notes Digital Construction 2022"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7b3p_nVe-fg"
      },
      "source": [
        "# Lecture 3 - Real Time Location Systems\n",
        "In this lecture you will get exposed to Python programming and location data. You will learn how to process the raw data output into tangible knowledge that can be used to analyze trajectories of construction assets.\n",
        "You will encounter several codeblocks with ***TO DO*** written in them. This is where you will have to follow the instructions and fill out the missing code before running the cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjY5qfhGfHF4"
      },
      "source": [
        "## Install dependencies\n",
        "For all colab exercises, we will be needing several python libraries. Some of them will be repeating dependencies for all exercises, while other might only be used in certain examples. For this lecture, we will install the following\n",
        "\n",
        "These libraries are part of the Kernel running i Colab and are therefore redy to be imported with the following lines\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "uLgXvAkUjHQe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL5cDX0FSliO"
      },
      "source": [
        "But how about a library that is not preinstalled ?? Unfortunately Traja is not.... \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "7Uo0uPdBVWYS"
      },
      "outputs": [],
      "source": [
        "# import traja"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAF0bKOcV5eE"
      },
      "source": [
        "How do we get around missing libraries this ?? \n",
        "Normally it would just mean that we had to install the library with the python package manager called pip, using the command 'pip install [package name]'\n",
        "\n",
        "If that is not possible, here is [Hint](https://colab.research.google.com/notebooks/snippets/importing_libraries.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTk7kxTbUgGG",
        "outputId": "6d386be1-37d6-4d83-99b8-4467f773f2e1"
      },
      "outputs": [],
      "source": [
        "#### TODO ####\n",
        "# Install Traja lib on the colab Kernel \n",
        "\n",
        "#### Sollution ####\n",
        "\n",
        "# !pip install Traja"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W93oxtHvUhR3"
      },
      "source": [
        "Hopefully you managed to install Traja and will be able to run the \"import traja\" line below. \n",
        "\n",
        "Most of the packages in python are well documented and an example is this library, which documentation is available in the following link.\n",
        "\n",
        "[Traja Docs](https://traja.readthedocs.io/en/latest/index.html)\n",
        "\n",
        "We are not going to use Traja just yet but now we knwo how to install libraries if these are not pre-installed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "q1BU84UWSqyr"
      },
      "outputs": [],
      "source": [
        "import traja\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVXFywR9XFfA"
      },
      "source": [
        "### Checkpoint 1\n",
        "Note the the following into a .txt file#\n",
        "\n",
        "1.   What command is used to install libraries in the python package manager?\n",
        "2.   What is needed in order to run the same command in colab?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea668Bi1Zog9"
      },
      "source": [
        "## Install the remaining libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "TgicpKafYJhw"
      },
      "outputs": [],
      "source": [
        "#### TODO ####\n",
        "#install : \n",
        "# lib1\n",
        "# lib 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the data\n",
        "For this part we are going to use pandas, which is a library for working with dataframes\n",
        "Pandas documentation: [Read function](https://pandas.pydata.org/docs/user_guide/io.html#io)\n",
        "\n",
        "The data that will be the subject for this lecture is RTLS data, more specifically UWB data recorded with the system that we used on the Demo day. \n",
        "The data is written as comma seperated data and the collomns correspond to:\n",
        "<Data Header>,<tag ID>,<X>,<Y>,<Z>,<battery>,<timestamp>,<unit>,<DQI>,<GDOP>,<Locate-Details>,<LF>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data_header</th>\n",
              "      <th>tag_id</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "      <th>battery</th>\n",
              "      <th>time</th>\n",
              "      <th>unit</th>\n",
              "      <th>dqi</th>\n",
              "      <th>gdop</th>\n",
              "      <th>locate_details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T</td>\n",
              "      <td>0025CB03</td>\n",
              "      <td>12.14</td>\n",
              "      <td>12.50</td>\n",
              "      <td>1.52</td>\n",
              "      <td>12</td>\n",
              "      <td>1.618572e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>0.11</td>\n",
              "      <td>G0.53</td>\n",
              "      <td>S01-S02-S04-S05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T</td>\n",
              "      <td>0025CB03</td>\n",
              "      <td>12.01</td>\n",
              "      <td>12.63</td>\n",
              "      <td>1.52</td>\n",
              "      <td>12</td>\n",
              "      <td>1.618572e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>0.29</td>\n",
              "      <td>G0.53</td>\n",
              "      <td>S01-S02-S04-S05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>T</td>\n",
              "      <td>0025CB03</td>\n",
              "      <td>12.06</td>\n",
              "      <td>12.67</td>\n",
              "      <td>1.52</td>\n",
              "      <td>12</td>\n",
              "      <td>1.618572e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>1.01</td>\n",
              "      <td>G0.53</td>\n",
              "      <td>S01-S02-S04-S05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>T</td>\n",
              "      <td>0025CB03</td>\n",
              "      <td>12.04</td>\n",
              "      <td>12.64</td>\n",
              "      <td>1.52</td>\n",
              "      <td>12</td>\n",
              "      <td>1.618572e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>0.30</td>\n",
              "      <td>G0.53</td>\n",
              "      <td>S01-S02-S04-S05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>T</td>\n",
              "      <td>0025CB03</td>\n",
              "      <td>12.01</td>\n",
              "      <td>12.62</td>\n",
              "      <td>1.52</td>\n",
              "      <td>12</td>\n",
              "      <td>1.618572e+09</td>\n",
              "      <td>1</td>\n",
              "      <td>0.29</td>\n",
              "      <td>G0.53</td>\n",
              "      <td>S04-S05-S01-S02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  data_header    tag_id      x      y     z  battery          time  unit  \\\n",
              "0           T  0025CB03  12.14  12.50  1.52       12  1.618572e+09     1   \n",
              "1           T  0025CB03  12.01  12.63  1.52       12  1.618572e+09     1   \n",
              "2           T  0025CB03  12.06  12.67  1.52       12  1.618572e+09     1   \n",
              "3           T  0025CB03  12.04  12.64  1.52       12  1.618572e+09     1   \n",
              "4           T  0025CB03  12.01  12.62  1.52       12  1.618572e+09     1   \n",
              "\n",
              "    dqi   gdop   locate_details  \n",
              "0  0.11  G0.53  S01-S02-S04-S05  \n",
              "1  0.29  G0.53  S01-S02-S04-S05  \n",
              "2  1.01  G0.53  S01-S02-S04-S05  \n",
              "3  0.30  G0.53  S01-S02-S04-S05  \n",
              "4  0.29  G0.53  S04-S05-S01-S02  "
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"A.txt\", names=[\"data_header\",\"tag_id\",\"x\",\"y\",\"z\",\"battery\",\"time\",\"unit\",\"dqi\",\"gdop\",\"locate_details\"], converters = {'tag_ID': str})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That is a lot of information... \n",
        "For our analysis we only need id, position(x,y), and time , therefore we drop the rest for now. but it is good to know that more data exists.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df[['tag_id','x','y','time']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That was reading the data, it may be interesting to figure out how many tags that are present in the data\n",
        "but are there any smart ways to do so ? \n",
        "It would be interesting to find the number of unique values in the \"tag_ID\" coloumn ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There exists 5 in the tag_ID column and their IDs are: \n",
            " ['0025CB03' '0025C9EB' '0025C9E6' '0025CAF6' '0025CB05']\n"
          ]
        }
      ],
      "source": [
        "unique_tags = df.tag_id.unique()\n",
        "number_of_unique_tags = len(unique_tags)\n",
        "print(f\"There exists {number_of_unique_tags} in the tag_ID column and their IDs are: \\n {unique_tags}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, what is the total duration of the data collected?\n",
        "Could ve use max and min value of a column? \n",
        "Does the time format seem wierd? [epoch time](https://www.epochconverter.com/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tag_id</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0025CB03</td>\n",
              "      <td>12.14</td>\n",
              "      <td>12.50</td>\n",
              "      <td>2021-04-16 11:16:20.170000128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0025CB03</td>\n",
              "      <td>12.01</td>\n",
              "      <td>12.63</td>\n",
              "      <td>2021-04-16 11:16:20.306999808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0025CB03</td>\n",
              "      <td>12.06</td>\n",
              "      <td>12.67</td>\n",
              "      <td>2021-04-16 11:16:20.441999872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0025CB03</td>\n",
              "      <td>12.04</td>\n",
              "      <td>12.64</td>\n",
              "      <td>2021-04-16 11:16:20.579000064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0025CB03</td>\n",
              "      <td>12.01</td>\n",
              "      <td>12.62</td>\n",
              "      <td>2021-04-16 11:16:20.716999936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4690</th>\n",
              "      <td>0025C9EB</td>\n",
              "      <td>7.86</td>\n",
              "      <td>2.75</td>\n",
              "      <td>2021-04-16 11:19:15.657000192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4691</th>\n",
              "      <td>0025CAF6</td>\n",
              "      <td>2.54</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2021-04-16 11:19:15.726000128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4692</th>\n",
              "      <td>0025CB03</td>\n",
              "      <td>11.93</td>\n",
              "      <td>12.45</td>\n",
              "      <td>2021-04-16 11:19:15.746000128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4693</th>\n",
              "      <td>0025CB05</td>\n",
              "      <td>1.51</td>\n",
              "      <td>11.68</td>\n",
              "      <td>2021-04-16 11:19:15.788999936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4694</th>\n",
              "      <td>0025C9EB</td>\n",
              "      <td>7.85</td>\n",
              "      <td>2.51</td>\n",
              "      <td>2021-04-16 11:19:15.792000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4695 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        tag_id      x      y                          time\n",
              "0     0025CB03  12.14  12.50 2021-04-16 11:16:20.170000128\n",
              "1     0025CB03  12.01  12.63 2021-04-16 11:16:20.306999808\n",
              "2     0025CB03  12.06  12.67 2021-04-16 11:16:20.441999872\n",
              "3     0025CB03  12.04  12.64 2021-04-16 11:16:20.579000064\n",
              "4     0025CB03  12.01  12.62 2021-04-16 11:16:20.716999936\n",
              "...        ...    ...    ...                           ...\n",
              "4690  0025C9EB   7.86   2.75 2021-04-16 11:19:15.657000192\n",
              "4691  0025CAF6   2.54   0.30 2021-04-16 11:19:15.726000128\n",
              "4692  0025CB03  11.93  12.45 2021-04-16 11:19:15.746000128\n",
              "4693  0025CB05   1.51  11.68 2021-04-16 11:19:15.788999936\n",
              "4694  0025C9EB   7.85   2.51 2021-04-16 11:19:15.792000000\n",
              "\n",
              "[4695 rows x 4 columns]"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.time = pd.to_datetime(df.time.values.astype(float),unit='s')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That format seems more normal \n",
        "Now we just need to find the min and max value [min and max](https://www.kite.com/python/answers/how-to-find-the-max-value-of-a-pandas-dataframe-column-in-python)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 days 00:02:55.621999872\n"
          ]
        }
      ],
      "source": [
        "min = df.time.min()\n",
        "max = df.time.max()\n",
        "duration = max-min\n",
        "print(duration)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we know how many tags that are in the data, and the duration\n",
        "\n",
        "what if we did this calculation for all tags, to see if they were active for the full duration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the data duration for tag 0025CB03 is  0 days 00:02:55.576000\n",
            "the data duration for tag 0025C9EB is  0 days 00:02:54.980999936\n",
            "the data duration for tag 0025C9E6 is  0 days 00:02:54.399000320\n",
            "the data duration for tag 0025CAF6 is  0 days 00:02:54.656000256\n",
            "the data duration for tag 0025CB05 is  0 days 00:02:45.862999808\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for tag in unique_tags:\n",
        "    min = df.loc[df.tag_id==tag].time.min()\n",
        "    max = df.loc[df.tag_id==tag].time.max()\n",
        "    duration = max-min\n",
        "    print(f\"the data duration for tag {tag} is  {duration}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Checkpoint 2\n",
        "\n",
        "What is the percentage duration of each tag relative to the tag that has the longest duration?\n",
        "\n",
        "Extend the above code to calculate this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 days 00:02:55.576000\n",
            "the data duration for tag 0025CB03 is 0 days 00:02:55.576000 ~ 100.0%\n",
            "the data duration for tag 0025C9EB is 0 days 00:02:54.980999936 ~ 99.66%\n",
            "the data duration for tag 0025C9E6 is 0 days 00:02:54.399000320 ~ 99.33%\n",
            "the data duration for tag 0025CAF6 is 0 days 00:02:54.656000256 ~ 99.48%\n",
            "the data duration for tag 0025CB05 is 0 days 00:02:45.862999808 ~ 94.47%\n"
          ]
        }
      ],
      "source": [
        "durations = []\n",
        "\n",
        "for tag in unique_tags:\n",
        "    min = df.loc[df.tag_id==tag].time.min()\n",
        "    max = df.loc[df.tag_id==tag].time.max()\n",
        "    duration = max-min\n",
        "    durations.append(duration)\n",
        "    # print(f\"the data duration for tag {tag} is  {duration}\")\n",
        "max_duration = np.max(durations)\n",
        "print(max_duration)\n",
        "for tag in unique_tags:\n",
        "    min = df.loc[df.tag_id==tag].time.min()\n",
        "    max = df.loc[df.tag_id==tag].time.max()\n",
        "    duration = max-min\n",
        "    pct_duration = round((duration/max_duration)*100,2)\n",
        "    print(f\"the data duration for tag {tag} is {duration} ~ {pct_duration}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting the trajectory data\n",
        "In python there are several libraries for plotting data, and Matplitlib is one of those. Matplotlib offers a great amout of features (if you are used to matlab, matplotlib can do the same, but maybe in a different way)\n",
        "\n",
        "[Matplotlib tutorial](https://matplotlib.org/stable/tutorials/introductory/pyplot.html)\n",
        "\n",
        "The tutorial contains this example, which we will take inspiration from (but slightly change):\n",
        "\n",
        "```\n",
        "import matplotlib.pyplot as plt\n",
        "names = ['group_a', 'group_b', 'group_c']\n",
        "values = [1, 10, 100]\n",
        "\n",
        "figure = plt.figure(figsize=(12, 4))\n",
        "\n",
        "ax1 = figure.add_subplot(131)\n",
        "ax1.bar(names, values)\n",
        "ax2 = figure.add_subplot(132)\n",
        "ax2.scatter(names, values)\n",
        "ax3 = figure.add_subplot(133)\n",
        "ax3.plot(names, values)\n",
        "figure.suptitle('Categorical Plotting')\n",
        "```\n",
        "\n",
        "NB. also part of slides!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [],
      "source": [
        "# try to run the code to get an overview of the different plotting funtions\n",
        "import matplotlib.pyplot as plt\n",
        "names = ['group_a', 'group_b', 'group_c']\n",
        "values = [1, 10, 100]\n",
        "\n",
        "figure = plt.figure(figsize=(12, 4))\n",
        "\n",
        "ax1 = figure.add_subplot(131)\n",
        "ax1.bar(names, values)\n",
        "ax2 = figure.add_subplot(132)\n",
        "ax2.scatter(names, values)\n",
        "ax3 = figure.add_subplot(133)\n",
        "ax3.plot(names, values)\n",
        "figure.suptitle('Categorical Plotting')\n",
        "figure.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x202924d0100>"
            ]
          },
          "execution_count": 184,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%matplotlib qt\n",
        "figure = plt.figure(figsize=(10,10))\n",
        "axs = figure.add_subplot(221)\n",
        "current_tag = None\n",
        "for tag in unique_tags:\n",
        "    current_tag  =  df.loc[df.tag_id==tag]\n",
        "    # you can access the x, and y values through the \"dot operator\", e.g., current_tag.X\n",
        "    # what kind of plot makes sense when plotting trajectories? \n",
        "    # Instead of using the defaul plt object we use the plot object called \"axs\", that is added to the figure called \"figure\" \n",
        "    #### Sollution ### \n",
        "    axs.plot(current_tag.x, current_tag.y,'-', label=tag,linewidth=1)\n",
        "    break\n",
        "# now set the title of the plot to somthing meaningfull e.g., incomming data, or unfiltered data\n",
        "# Also pleae add a label for the x, and y-axis e.g, X [m] and Y [m]\n",
        "# and make sure that the legends are shown \n",
        "#### Sollution ### \n",
        "axs.set_title(\"Original data\")\n",
        "axs.set_xlabel(\"X [m]\")\n",
        "axs.set_ylabel(\"Y [m]\")\n",
        "axs.legend()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Checkpoint 3 \n",
        "Does you plot look similar to this ? (**not neccesarily the colors)\n",
        "\n",
        "<img src=\"Images/CP3.png\" style=\"padding-bottom:5px;\" height=\"300px\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Moving on to the next step of handling data in this programming approach\n",
        "the data we just plotted seems to be rather messy and to contain quite some noise\n",
        "\n",
        "Any filters that we could apply ? how would a moving average filter effect the data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fig, axs = plt.subplots(2)\n",
        "axs = figure.add_subplot(222)\n",
        "MM_current_tag = current_tag.copy()\n",
        "MM_current_tag.x = current_tag.x.rolling(10).mean()\n",
        "MM_current_tag.y = current_tag.y.rolling(10).mean()\n",
        "axs.plot(MM_current_tag.x, MM_current_tag.y,'-', label=tag,linewidth=1)\n",
        "\n",
        "axs.set_title(\"Moving Avg. 10\")\n",
        "axs.set_xlabel(\"X [m]\")\n",
        "axs.set_ylabel(\"Y [m]\")\n",
        "axs.legend()\n",
        "figure.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [],
      "source": [
        "axs = figure.add_subplot(223)\n",
        "MM_current_tag = current_tag.copy()\n",
        "MM_current_tag.x = current_tag.x.rolling(20).mean()\n",
        "MM_current_tag.y = current_tag.y.rolling(20).mean()\n",
        "axs.plot(MM_current_tag.x, MM_current_tag.y,'-', label=tag,linewidth=1)\n",
        "\n",
        "axs.set_title(\"Moving Avg. 20\")\n",
        "axs.set_xlabel(\"X [m]\")\n",
        "axs.set_ylabel(\"Y [m]\")\n",
        "axs.legend()\n",
        "figure.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [],
      "source": [
        "axs = figure.add_subplot(224)\n",
        "MM_current_tag = current_tag.copy()\n",
        "MM_current_tag.x = current_tag.x.rolling(30).mean()\n",
        "MM_current_tag.y = current_tag.y.rolling(30).mean()\n",
        "axs.plot(MM_current_tag.x, MM_current_tag.y,'-', label=tag,linewidth=1)\n",
        "\n",
        "axs.set_title(\"Moving Avg. 30\")\n",
        "axs.set_xlabel(\"X [m]\")\n",
        "axs.set_ylabel(\"Y [m]\")\n",
        "axs.legend()\n",
        "figure.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Describe with words, how a simple moving average effect the data, and its validity\n",
        "#### asd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Now lets try build our own filtering algoritm\n",
        "could we use some domain knowledge about where the tags were placed\n",
        "\n",
        "what about filtering based on speed ? \n",
        "what about filtering based on displacement ?\n",
        "An easy way to get this information from a trajectory is to use [get_derivatives()](https://traja.readthedocs.io/en/latest/calculations.html#derivatives)\n",
        "\n",
        "How do we \"mask\" data ? \n",
        "\n",
        "# add description of data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_copy = df.copy()\n",
        "df_copy.time = (df_copy.time.values.astype(float))*10**-9\n",
        "\n",
        "\n",
        "figure = plt.figure(figsize=(10,10))\n",
        "axs = figure.add_subplot(221)\n",
        "\n",
        "\n",
        "for tag in unique_tags:\n",
        "    df_tag = df_copy.loc[df_copy.tag_id == tag]\n",
        "    #just to show that we are dealing with the same tag\n",
        "    axs.plot(df_tag.x, df_tag.y,'-', label=tag,linewidth=1)\n",
        "    break\n",
        "axs.set_title(\"Original Data\")\n",
        "axs.set_xlabel(\"X [m]\")\n",
        "axs.set_ylabel(\"Y [m]\")\n",
        "axs.legend()\n",
        "\n",
        "\n",
        "\n",
        "derivatives = df_tag.traja.get_derivatives() \n",
        "derivatives.head()\n",
        "mask1 = derivatives.speed<2\n",
        "mask2 = derivatives.speed>-2 \n",
        "maskspeed  = mask1 & mask2\n",
        "df_tag_speed = df_tag.loc[maskspeed]\n",
        "\n",
        "axs = figure.add_subplot(222)   \n",
        "axs.plot(df_tag_speed.x, df_tag_speed.y,'-', label=tag,linewidth=1)\n",
        "axs.set_title(\"filter based on speed 2m/s\")\n",
        "axs.set_xlabel(\"X [m]\")\n",
        "axs.set_ylabel(\"Y [m]\")\n",
        "axs.legend()\n",
        "figure.show()\n",
        "\n",
        "mask1 = derivatives.displacement<1\n",
        "mask2 = derivatives.displacement>-1 \n",
        "maskdisplace  = mask1 & mask2\n",
        "df_disp = df_tag_speed.loc[maskdisplace]\n",
        "\n",
        "axs = figure.add_subplot(223)   \n",
        "axs.plot(df_disp.x, df_disp.y,'-', label=tag,linewidth=1)\n",
        "axs.set_title(\"Displacement 1m\")\n",
        "axs.set_xlabel(\"X [m]\")\n",
        "axs.set_ylabel(\"Y [m]\")\n",
        "axs.legend()\n",
        "figure.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## trying to add another of the shelf filtering algorithm\n",
        "The second filtering algorithm is a more sofisticated one. It is called [Savitzky–Golay](https://www.wikiwand.com/en/Savitzky%E2%80%93Golay_filter). \n",
        "It can be compared to fitting the data to a higher degree polynomial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {},
      "outputs": [],
      "source": [
        "axs = figure.add_subplot(224)\n",
        "sg_filtered = traja.smooth_sg(df_tag_speed,w=7) \n",
        "axs.plot(sg_filtered.x, sg_filtered.y,'-', label=tag,linewidth=1)\n",
        "axs.set_title(\"Savitzky-Golay filtering\")\n",
        "axs.set_xlabel(\"X [m]\")\n",
        "axs.set_ylabel(\"Y [m]\")\n",
        "axs.legend()\n",
        "figure.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Playing around with the filter \n",
        "Try to change the polynomial degree of the filter, and see the difference. \n",
        "\n",
        "What effet does the polynomial degree have? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lets create some functions to handle this\n",
        "Here is some info on [creating funcitons](https://www.w3schools.com/python/python_functions.asp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_dataframe(dataframe_to_filter, sg_window=7):\n",
        "    data_copy_in =dataframe_to_filter.copy()\n",
        "    data_copy_in.time = (data_copy_in.time.values.astype(float))*10**-9\n",
        "    copy_df=pd.DataFrame(columns=data_copy_in.columns)\n",
        "    for tag in data_copy_in.tag_id.unique():\n",
        "        df_tag = data_copy_in.loc[data_copy_in.tag_id == tag]\n",
        "        # print(len(df_tag))\n",
        "        derivatives = df_tag.traja.get_derivatives() \n",
        "        #speed \n",
        "        mask1 = derivatives.speed<2\n",
        "        mask2 = derivatives.speed>-2 \n",
        "        maskspeed  = mask1 & mask2\n",
        "        df_tag = df_tag.loc[maskspeed]\n",
        "        #displacement\n",
        "        mask1 = derivatives.displacement<1\n",
        "        mask2 = derivatives.displacement>-1 \n",
        "        maskdisplace  = mask1 & mask2\n",
        "        df_tag = df_tag.loc[maskdisplace]\n",
        "        #sg filtering\n",
        "        if len(df_tag)< sg_window:\n",
        "            continue\n",
        "        df_tag = traja.smooth_sg(df_tag,w=sg_window)\n",
        "        copy_df = copy_df.append(df_tag)\n",
        "    return copy_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Are there others?\n",
        "\n",
        "Do you happen to know other location data filtering algorithms?\n",
        "\n",
        "What is the most used one for trajectory data?\n",
        "\n",
        "Are there any python implementations available ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# In area analyis\n",
        "What if we wanted to investigate how much time a tag (person) spend in a specific area? e.g., if an area is off limit due to safety resriction, progress analysis or somthing else\n",
        "Here we have at least two options:\n",
        "1. To use the mask approach that we just did - This is fine as we want to check a square bounding box\n",
        "2. Use a polygon, and check wether a point is inside or not - handy if we wanna check more sophisticated areas \n",
        "\n",
        "We will start with the first approach for one tag only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Visit #0 had duration of 9.27 s\n",
            "Visit #1 had duration of 10.5 s\n",
            "Visit #2 had duration of 0.0 s\n",
            "Visit #3 had duration of 5.85 s\n",
            "Visit #4 had duration of 0.82 s\n",
            "Visit #5 had duration of 17.44 s\n"
          ]
        }
      ],
      "source": [
        "# exclude data from other tags than 0025CB03 from the SG-filtered data\n",
        "mask_id = sg_filtered.tag_id == \"0025CB03\"\n",
        "data_for_tag = sg_filtered.loc[mask_id]\n",
        "area = {\n",
        "    \"x_min\":11,\n",
        "    \"y_min\":11,\n",
        "    \"x_max\":13,\n",
        "    \"y_max\":13\n",
        "}\n",
        "# print(area[\"x_min\"])\n",
        "mask_x  = ((sg_filtered.x >= area[\"x_min\"]) & (sg_filtered.x<= area[\"x_max\"]))\n",
        "\n",
        "mask_y  = ((sg_filtered.y >= area[\"y_min\"]) & (sg_filtered.y <= area[\"y_max\"]))\n",
        "\n",
        "mask_inside_area = (mask_x & mask_y)\n",
        "\n",
        "data_inside_area = sg_filtered.loc[mask_inside_area]\n",
        "list_of_continues_visits=[]\n",
        "current_visit=[]\n",
        "for idx, row in enumerate(data_inside_area.iterrows()):\n",
        "    # print(row[1][\"time\"])\n",
        "    time_for_row =  row[1][\"time\"]\n",
        "    if not current_visit: # check if empty\n",
        "        current_visit.append(time_for_row)\n",
        "        continue\n",
        "    elif time_for_row-current_visit[-1]<1: # less than one seccond\n",
        "        current_visit.append(time_for_row)\n",
        "        continue\n",
        "    elif time_for_row-current_visit[-1]>=1: # more than or equal to one seccond\n",
        "        if len(current_visit)>1:\n",
        "            list_of_continues_visits.append(current_visit)\n",
        "        current_visit = [] #empty current visit, and continue\n",
        "\n",
        "for idx, visit in enumerate(list_of_continues_visits):\n",
        "    duration  = visit[-1]-visit[1]\n",
        "    print(f\"Visit #{idx} had duration of {round(duration,2)} s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# How about a proximity analysis \n",
        "There can be several reasons to be interested in a persons proximity to objects, heavy macinery such as crane hook, excavator , or event other persons(e.g., Covid-19 regualtion) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "536it [00:39, 13.64it/s]\n"
          ]
        }
      ],
      "source": [
        "from math import sqrt\n",
        "from tqdm import tqdm\n",
        "filtered_df = filter_dataframe(df)\n",
        "tag_under_investigation = \"0025CB03\"\n",
        "mask_id = filtered_df.tag_id == tag_under_investigation\n",
        "data_for_tag = filtered_df.loc[mask_id]\n",
        "remaining_data = filtered_df.loc[~mask_id]\n",
        "incidents = pd.DataFrame(columns=remaining_data.columns)\n",
        "\n",
        "for row in tqdm(data_for_tag.iterrows()):\n",
        "    time = row[1][\"time\"]\n",
        "    x = row[1][\"x\"]\n",
        "    y = row[1][\"y\"]\n",
        "    for row_2 in remaining_data.iterrows():\n",
        "        time_2 = row_2[1][\"time\"]\n",
        "        x_2 = row_2[1][\"x\"]\n",
        "        y_2 = row_2[1][\"y\"]\n",
        "        if abs(time-time_2)<1:\n",
        "            distance = sqrt((x-x_2)**2 + (y-y_2)**2)\n",
        "            if distance <= 1:\n",
        "                incidents = incidents.append(row_2[1])\n",
        "\n",
        "figure = plt.figure(figsize=(10,10))\n",
        "axs = figure.add_subplot(111)\n",
        "\n",
        "axs.plot(data_for_tag.x, data_for_tag.y,'-', label=tag,linewidth=1)\n",
        "axs.plot(incidents.x, incidents.y,'r*', label=\"Incidents\",linewidth=1)\n",
        "axs.set_title(\"incidents\")\n",
        "axs.set_xlabel(\"X [m]\")\n",
        "axs.set_ylabel(\"Y [m]\")\n",
        "axs.legend()\n",
        "figure.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Incident report analysis\n",
        "Can we say somthing more detailed about the incidents ?\n",
        "\n",
        "1. How many incidents were mad by each individual tag?\n",
        "2. Turn te above into a function and run in for loop and make the analysis for all tags\n",
        "3. Print a nice report using the print(f\"text {variable}\") way\n",
        "4. Create a confusion matrix-plot for easier overview\n",
        "5. Calculate the number of incidents in [20cm, 40cm, 60cm, 80cm, 100cm] and make bar-plot "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tag_id 0025C9EB had 11 proximity incidents with 0025CB03\n",
            "tag_id 0025C9E6 had 4 proximity incidents with 0025CB03\n",
            "tag_id 0025CAF6 had 0 proximity incidents with 0025CB03\n",
            "tag_id 0025CB05 had 6 proximity incidents with 0025CB03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "536it [00:38, 13.89it/s]\n",
            "732it [00:48, 14.94it/s]\n",
            "674it [00:46, 14.39it/s]\n",
            "603it [00:43, 13.81it/s]\n",
            "161it [00:14, 11.29it/s]\n"
          ]
        }
      ],
      "source": [
        "# 1\n",
        "for tag in unique_tags:\n",
        "    if tag == tag_under_investigation:\n",
        "        continue\n",
        "    mask_id = (incidents.tag_id == tag)\n",
        "    print(f\"tag_id {tag} had {mask_id.sum()} proximity incidents with {tag_under_investigation}\")\n",
        "\n",
        "# 2\n",
        "def proximity_analysis(df):\n",
        "    result = []\n",
        "    for tag in unique_tags:\n",
        "        tag_under_investigation = tag\n",
        "        mask_id = filtered_df.tag_id == tag_under_investigation\n",
        "        data_for_tag = filtered_df.loc[mask_id]\n",
        "        remaining_data = filtered_df.loc[~mask_id]\n",
        "        incidents = pd.DataFrame(columns=remaining_data.columns)\n",
        "        for row in tqdm(data_for_tag.iterrows()):\n",
        "            time = row[1][\"time\"]\n",
        "            x = row[1][\"x\"]\n",
        "            y = row[1][\"y\"]\n",
        "            for row_2 in remaining_data.iterrows():\n",
        "                time_2 = row_2[1][\"time\"]\n",
        "                x_2 = row_2[1][\"x\"]\n",
        "                y_2 = row_2[1][\"y\"]\n",
        "                if abs(time-time_2)<1:\n",
        "                    distance = sqrt((x-x_2)**2 + (y-y_2)**2)\n",
        "                    if distance <= 1:\n",
        "                        incidents = incidents.append(row_2[1])\n",
        "        dictionary = {\n",
        "            \"analyzed_id\":tag,\n",
        "            \"data_frame\":incidents\n",
        "        }\n",
        "        result.append(dictionary)\n",
        "    return result\n",
        "result_list = proximity_analysis(filtered_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tag_id 0025CB03 had 21 incidents in total\n",
            "\t 11 proximity incidents with 0025C9EB\n",
            "\t 4 proximity incidents with 0025C9E6\n",
            "\t 0 proximity incidents with 0025CAF6\n",
            "\t 6 proximity incidents with 0025CB05\n",
            "tag_id 0025C9EB had 44 incidents in total\n",
            "\t 11 proximity incidents with 0025CB03\n",
            "\t 15 proximity incidents with 0025C9E6\n",
            "\t 3 proximity incidents with 0025CAF6\n",
            "\t 15 proximity incidents with 0025CB05\n",
            "tag_id 0025C9E6 had 30 incidents in total\n",
            "\t 4 proximity incidents with 0025CB03\n",
            "\t 15 proximity incidents with 0025C9EB\n",
            "\t 3 proximity incidents with 0025CAF6\n",
            "\t 8 proximity incidents with 0025CB05\n",
            "tag_id 0025CAF6 had 7 incidents in total\n",
            "\t 0 proximity incidents with 0025CB03\n",
            "\t 3 proximity incidents with 0025C9EB\n",
            "\t 3 proximity incidents with 0025C9E6\n",
            "\t 1 proximity incidents with 0025CB05\n",
            "tag_id 0025CB05 had 30 incidents in total\n",
            "\t 6 proximity incidents with 0025CB03\n",
            "\t 15 proximity incidents with 0025C9EB\n",
            "\t 8 proximity incidents with 0025C9E6\n",
            "\t 1 proximity incidents with 0025CAF6\n"
          ]
        }
      ],
      "source": [
        "#3\n",
        "def report_incidents(incidents_result):\n",
        "    for dictionary in incidents_result:\n",
        "        tag_under_investigation = dictionary[\"analyzed_id\"]\n",
        "        incidents = dictionary[\"data_frame\"]\n",
        "        print(f\"tag_id {tag_under_investigation} had {len(incidents)} incidents in total\")\n",
        "        for tag in unique_tags:\n",
        "            if tag == tag_under_investigation:\n",
        "                continue\n",
        "            mask_id = (incidents.tag_id == tag)\n",
        "            print(f\"\\t {mask_id.sum()} proximity incidents with {tag}\")\n",
        "report_incidents(result_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tag_id 0025CB03 had 21 incidents in total\n",
            "\t 0 proximity incidents with 0025CB03\n",
            "\t 11 proximity incidents with 0025C9EB\n",
            "\t 4 proximity incidents with 0025C9E6\n",
            "\t 0 proximity incidents with 0025CAF6\n",
            "\t 6 proximity incidents with 0025CB05\n",
            "tag_id 0025C9EB had 44 incidents in total\n",
            "\t 11 proximity incidents with 0025CB03\n",
            "\t 0 proximity incidents with 0025C9EB\n",
            "\t 15 proximity incidents with 0025C9E6\n",
            "\t 3 proximity incidents with 0025CAF6\n",
            "\t 15 proximity incidents with 0025CB05\n",
            "tag_id 0025C9E6 had 30 incidents in total\n",
            "\t 4 proximity incidents with 0025CB03\n",
            "\t 15 proximity incidents with 0025C9EB\n",
            "\t 0 proximity incidents with 0025C9E6\n",
            "\t 3 proximity incidents with 0025CAF6\n",
            "\t 8 proximity incidents with 0025CB05\n",
            "tag_id 0025CAF6 had 7 incidents in total\n",
            "\t 0 proximity incidents with 0025CB03\n",
            "\t 3 proximity incidents with 0025C9EB\n",
            "\t 3 proximity incidents with 0025C9E6\n",
            "\t 0 proximity incidents with 0025CAF6\n",
            "\t 1 proximity incidents with 0025CB05\n",
            "tag_id 0025CB05 had 30 incidents in total\n",
            "\t 6 proximity incidents with 0025CB03\n",
            "\t 15 proximity incidents with 0025C9EB\n",
            "\t 8 proximity incidents with 0025C9E6\n",
            "\t 1 proximity incidents with 0025CAF6\n",
            "\t 0 proximity incidents with 0025CB05\n",
            "[[0, 11, 4, 0, 6], [11, 0, 15, 3, 15], [4, 15, 0, 3, 8], [0, 3, 3, 0, 1], [6, 15, 8, 1, 0]]\n"
          ]
        }
      ],
      "source": [
        "#4\n",
        "import seaborn as sn\n",
        "def generate_confusion_matrix (incidents_result):\n",
        "    matrix = []\n",
        "    for dictionary in incidents_result:\n",
        "        tag_under_investigation = dictionary[\"analyzed_id\"]\n",
        "        incidents = dictionary[\"data_frame\"]\n",
        "        print(f\"tag_id {tag_under_investigation} had {len(incidents)} incidents in total\")\n",
        "        row = []\n",
        "        for tag in unique_tags:\n",
        "            # if tag == tag_under_investigation:\n",
        "            #     continue\n",
        "            mask_id = (incidents.tag_id == tag)\n",
        "            row.append(mask_id.sum())\n",
        "            print(f\"\\t {mask_id.sum()} proximity incidents with {tag}\")\n",
        "        matrix.append(row)\n",
        "\n",
        "    return matrix\n",
        "matrix = generate_confusion_matrix(result_list)\n",
        "print(matrix)\n",
        "df_cm = pd.DataFrame(matrix, index = [i for i in unique_tags],\n",
        "                  columns = [i for i in unique_tags])\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "536it [00:39, 13.60it/s]\n",
            "732it [00:51, 14.30it/s]\n",
            "674it [00:48, 13.81it/s]\n",
            "603it [00:45, 13.30it/s]\n",
            "161it [00:14, 10.92it/s]\n"
          ]
        }
      ],
      "source": [
        "#5\n",
        "def proximity_analysis(df):\n",
        "    result = []\n",
        "    for tag in unique_tags:\n",
        "        tag_under_investigation = tag\n",
        "        mask_id = filtered_df.tag_id == tag_under_investigation\n",
        "        data_for_tag = filtered_df.loc[mask_id]\n",
        "        remaining_data = filtered_df.loc[~mask_id]\n",
        "        incidents = pd.DataFrame(columns=remaining_data.columns)\n",
        "        distances = []\n",
        "        for row in tqdm(data_for_tag.iterrows()):\n",
        "            time = row[1][\"time\"]\n",
        "            x = row[1][\"x\"]\n",
        "            y = row[1][\"y\"]\n",
        "            for row_2 in remaining_data.iterrows():\n",
        "                time_2 = row_2[1][\"time\"]\n",
        "                x_2 = row_2[1][\"x\"]\n",
        "                y_2 = row_2[1][\"y\"]\n",
        "                if abs(time-time_2)<1:\n",
        "                    distance = sqrt((x-x_2)**2 + (y-y_2)**2)\n",
        "                    if distance <= 1:\n",
        "                        distances.append(distance)\n",
        "                        incidents = incidents.append(row_2[1])\n",
        "        incidents[\"distances\"]=distances\n",
        "        dictionary = {\n",
        "            \"analyzed_id\":tag,\n",
        "            \"data_frame\":incidents\n",
        "        }\n",
        "        result.append(dictionary)\n",
        "    return result\n",
        "result_list = proximity_analysis(filtered_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {},
      "outputs": [],
      "source": [
        "#5 continued\n",
        "result_dictionary = {\n",
        "    \"0-20cm\":0,\n",
        "    \"21-40cm\":0,\n",
        "    \"41-60cm\":0,\n",
        "    \"61-80cm\":0,\n",
        "    \"81-100cm\":0\n",
        "}\n",
        "for dictionary in result_list:\n",
        "    incidents = dictionary[\"data_frame\"]\n",
        "    mask_20 = ((incidents.distances>=.0)&(incidents.distances<=.20))\n",
        "    mask_40 = ((incidents.distances>=.21)&(incidents.distances<=.40))\n",
        "    mask_60 = ((incidents.distances>=.41)&(incidents.distances<=.60))\n",
        "    mask_80 = ((incidents.distances>=.61)&(incidents.distances<=.80))\n",
        "    mask_100 = ((incidents.distances>=.81)&(incidents.distances<=1))\n",
        "    result_dictionary[\"0-20cm\"] += mask_20.sum()\n",
        "    result_dictionary[\"21-40cm\"] += mask_40.sum()\n",
        "    result_dictionary[\"41-60cm\"] += mask_60.sum()\n",
        "    result_dictionary[\"61-80cm\"] += mask_80.sum()\n",
        "    result_dictionary[\"81-100cm\"] += mask_100.sum()\n",
        "\n",
        "plt.figure(figsize = (10,7))\n",
        "plt.bar(result_dictionary.keys(),result_dictionary.values())\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DigitalConstructionLecture1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
